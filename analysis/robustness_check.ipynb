{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from matplotlib import container\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/gpt_high_conf.csv', index_col=0)\n",
    "repl = ['tiiuae_', '_responses.json','mistralai_','meta-llama_','_responses.json']\n",
    "df['model'] = df['model'].replace(repl,  '', regex=True).str.lower()\n",
    "# Drop empty responses\n",
    "df = df[df['answer'].notna()]\n",
    "subset = df[df['label']!='unrelated'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset[subset['statement']!='statement']\n",
    "pd.unique(subset['statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(subset['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [m for m in pd.unique(subset['model']) if 'gpt_4' in m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "groups = ['opposite', 'reformulation']\n",
    "\n",
    "gpt_bias_dict = {m:{} for m in models}\n",
    "gpt_bias_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    model_subset = subset[subset['model'] == m]\n",
    "    for g in groups:\n",
    "        gpt_bias_dict[m][g] = (compute_bias(model_subset, 'statement', g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/formulations_high_conf.csv', index_col=0)\n",
    "repl = ['tiiuae_', '_responses.json','mistralai_','meta-llama_','_responses.json']\n",
    "df['model'] = df['model'].replace(repl,  '', regex=True).str.lower()\n",
    "# Drop empty responses\n",
    "df = df[df['answer'].notna()]\n",
    "df = df[df['prefix'].notna()]\n",
    "subset = df[df['label']!='unrelated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['statement_type'] = subset['prefix'].apply(lambda x: 'opposite' if 'opposite' in x else 'reformulation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(pd.unique(subset['model']))\n",
    "groups = ['opposite', 'reformulation']\n",
    "\n",
    "llama_bias_dict = {m:{} for m in models}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.loc[subset['statement_type']== 'opposite', 'label'] = subset.loc[subset['statement_type']== 'opposite']['label'].replace({'agree':'disagree', 'disagree':'agree'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    model_subset = subset[subset['model'] == m]\n",
    "    for g in groups:\n",
    "        llama_bias_dict[m][g] = compute_bias(model_subset, 'statement_type', g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_bias = pd.DataFrame(llama_bias_dict).T.reset_index(names='model')\n",
    "llama_bias['model'] = llama_bias['model'].str.replace('responses_', '').str.replace('.json', '')\n",
    "llama_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_bias = pd.DataFrame(gpt_bias_dict).T.reset_index(names='model')\n",
    "llama_bias['model'] = llama_bias['model'].str.replace('responses_', '').str.replace('.json', '')\n",
    "gpt_bias['model'] = gpt_bias['model'].str.replace('gpt_4', 'gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=gpt_bias, right=llama_bias, on='model', suffixes=['_gpt', '_llama'])\n",
    "compare = pd.DataFrame({'compare' : df['model'], 'Opposite': pd.NA, 'Reformulation': pd.NA})\n",
    "compare.Opposite = df['opposite_llama'].abs() -df['opposite_gpt'].abs()\n",
    "\n",
    "compare.Reformulation = df['reformulation_llama'].abs() -df['reformulation_gpt'].abs()\n",
    "compare.to_csv('./data/formulation_compare.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
